from flask import Flask, request, jsonify
from flask_cors import CORS
import pandas as pd
from catboost import CatBoostClassifier
from ai.feature import analyze_reviews
import requests
from io import BytesIO
from PIL import Image
import numpy as np
import cv2
import pytesseract
import base64
import joblib
from tensorflow.keras.models import load_model
from fetcher import fetch_main_container_images_only
from openai import OpenAI
import requests

app = Flask(__name__)
CORS(app)

# --- ëª¨ë¸ ë¡œë“œ ---
catboost_model = CatBoostClassifier()
catboost_model.load_model("ai/detection_model/ad_detection_model.cbm")

anomaly_model = load_model("ai/abnomaly_detection_model/anomaly_lstm_autoencoder.keras")
scaler = joblib.load("ai/abnomaly_detection_model/scaler_lstm.pkl")

def merge_images_vertically(img_urls):
    images = []
    sizes = []

    for url in img_urls:
        try:
            res = requests.get(url, timeout=5)
            img = Image.open(BytesIO(res.content))

            if img.mode != "RGBA":
                img = img.convert("RGBA")  # ì•ŒíŒŒ ë³´ì¡´ìš© ë³€í™˜

            w, h = img.size
            sizes.append((w, h))
            images.append(img)
        except Exception as e:
            print(f"[ì´ë¯¸ì§€ ë¡œë”© ì‹¤íŒ¨] {url} / {e}")
            continue

    if not images:
        return None, []

    # í‰ê·  (w + h)
    wh_sums = [w + h for w, h in sizes]
    avg_wh = sum(wh_sums) / len(wh_sums)
    print(f"ğŸ“ í‰ê·  (W+H): {avg_wh:.1f}")

    resized_images = []
    for img, (w, h) in zip(images, sizes):
        current_wh = w + h
        ratio = avg_wh / current_wh
        new_w = int(w * ratio)
        new_h = int(h * ratio)
        resized = img.resize((new_w, new_h))
        resized_images.append(resized)

    max_width = max(img.width for img in resized_images)
    total_height = sum(img.height for img in resized_images)

    # RGBA ëª¨ë“œë¡œ íˆ¬ëª… ë°°ê²½ ìœ ì§€
    merged = Image.new("RGBA", (max_width, total_height), (0, 0, 0, 0))  # ì™„ì „ íˆ¬ëª…

    y_offset = 0
    for img in resized_images:
        x_offset = int((max_width - img.width) / 2)
        merged.paste(img, (x_offset, y_offset), mask=img)  # ì•ŒíŒŒ ì ìš©
        y_offset += img.height

    # ì¸ì½”ë”©
    buffer = BytesIO()
    merged.save(buffer, format="PNG")
    base64_img = base64.b64encode(buffer.getvalue()).decode("utf-8")

    return base64_img, resized_images

@app.route("/predict", methods=["POST"])
def predict():
    data = request.json
    url = data.get("url")

    if not url:
        return jsonify({"error": "url ëˆ„ë½ë¨"}), 400

    # âœ… fetcherë¡œ ë³¸ë¬¸ + ì´ë¯¸ì§€ ì „ë¶€ ì„œë²„ì—ì„œ ì§ì ‘ ê°€ì ¸ì˜¤ê¸°
    fetched = fetch_main_container_images_only(url)
    text = fetched["text"]
    img_urls = fetched["images"]

    if not text or text.startswith("âŒ") or len(text.strip()) < 10:
        return jsonify({"error": "ë³¸ë¬¸ ì—†ìŒ"})

    # --- í”¼ì²˜ ìƒì„± ---
    df = pd.DataFrame({
        "text": [text],
        "image_count": [len(img_urls)]
    })
    df = analyze_reviews(df)
    feature_cols = [col for col in df.columns if col not in ['text', 'is_ad', 'image_count']]
    df[feature_cols] = df[feature_cols].fillna(0)

    client = OpenAI(api_key="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")

    # ì´ë¯¸ì§€ ë³‘í•© + GPT OCR ìš”ì²­
    base64_img, raw_images = merge_images_vertically(img_urls)

    ocr_texts, ocr_images = [], []
    if base64_img:
        image_data_url = f"data:image/png;base64,{base64_img}"
        question = "ì´ ì´ë¯¸ì§€ ë‚´ìš©ì„ í…ìŠ¤íŠ¸ë¡œ ì¶”ì¶œí•´ì¤˜. ë‹¤ë¥¸ ë§ì€ ì ˆëŒ€ í•˜ì§€ ë§ê³  ì•ˆì— í…ìŠ¤íŠ¸ë§Œ ë§í•´. í…ìŠ¤íŠ¸ê°€ ì—†ìœ¼ë©´ 'í…ìŠ¤íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤' ì´ë ‡ê²Œë§Œ ë§í•´."

        try:
            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {
                        "role": "user",
                        "content": [
                            {"type": "text", "text": question},
                            {"type": "image_url", "image_url": {"url": image_data_url}}
                        ]
                    }
                ],
                max_tokens=600
            )
            gpt_ocr = response.choices[0].message.content.strip()
            ocr_texts.append(gpt_ocr)
            ocr_images.append(base64_img)  # ë³‘í•© ì´ë¯¸ì§€ 1ì¥ë§Œ ìˆìŒ
        except Exception as e:
            ocr_texts.append(f"[GPT OCR ì‹¤íŒ¨] {str(e)}")
            ocr_images.append(None)
    else:
        ocr_texts.append("[ì´ë¯¸ì§€ ë³‘í•© ì‹¤íŒ¨]")
        ocr_images.append(None)

    # --- ê´‘ê³  í‚¤ì›Œë“œ ê¸°ë°˜ íŒë‹¨ ---
    ad_keywords = ["í˜‘ì°¬", "ì œê³µ", "ê´‘ê³ ", "ì§€ì›ë°›ì•„", "ì œê³µë°›ì•„", "í˜‘ì°¬ë°›ì•„", "í›„ì›", "í™ë³´", "ì›ê³ ë£Œ", "ì†Œì •ì˜"]
    ocr_combined = " ".join(ocr_texts)
    if any(kw in ocr_combined for kw in ad_keywords):
        return jsonify({
            "label": 1,
            "prob": 1.0,
            "anomaly_detected": None,
            "anomaly_score": None,
            "ocr_texts": ocr_texts,
            "ocr_images": ocr_images,
            "imgUrls": img_urls
        })

    # --- CatBoost ì˜ˆì¸¡ + ì´ìƒ íƒì§€ ---
    prob = float(catboost_model.predict_proba(df[feature_cols])[0][1])
    anomaly_score = None
    anomaly_detected = False

    if prob <= 0.3:
        label = 0
    elif prob >= 0.7:
        label = 1
    else:
        X_scaled = scaler.transform(df[feature_cols])
        X_scaled = X_scaled.reshape((X_scaled.shape[0], 1, X_scaled.shape[1]))
        recon = anomaly_model.predict(X_scaled)
        mse = float(np.mean(np.square(X_scaled - recon), axis=(1, 2))[0])
        anomaly_score = mse
        anomaly_detected = mse > 0.05
        label = 1 if anomaly_detected else 0

    return jsonify({
        "label": label,
        "prob": prob,
        "anomaly_detected": anomaly_detected,
        "anomaly_score": anomaly_score,
        "ocr_texts": ocr_texts,
        "ocr_images": ocr_images,
        "imgUrls": img_urls
    })

if __name__ == "__main__":
    app.run(port=5000, debug=True)
